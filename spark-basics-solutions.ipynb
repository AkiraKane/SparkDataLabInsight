{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving toward a join action, we can use the map() method to create Key/Value pairs from the tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we create an RDD from a csv stored in s3, and use the collect() action, which returns an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usersWithGenderJoinedRDD = usersRDD.join(gendersRDD)\n",
    "usersWithGenderJoinedRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we'll explore a few methods in Spark Core\n",
    "### Creating RDDs, collect(), map(), join(), reduceByKey(), aggregateByKey(), and filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The collect action causes data to flow across the network from the worker nodes to the master (where you are running the jupyter notebook, or your data analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a csv of id, users\n",
    "rawUsersRDD = sc.textFile(\"s3n://insight-spark-after-dark/users-sm.csv\")\n",
    "rawUsersRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_tup(record):\n",
    "    tokens = record.split(\",\")\n",
    "    return (int(tokens[0]), str(tokens[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll start with an online-dating dataset, described here: https://sites.google.com/a/insightdatascience.com/spark-lab/s3-data/dating-profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usersRDD = rawUsersRDD.map(rec_tup)\n",
    "usersRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some further questions to get to grips with Spark basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a csv of id, genders\n",
    "rawGendersRDD = sc.textFile(\"s3n://insight-spark-after-dark/gender-sm.csv\")\n",
    "rawGendersRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: There exists another zipped csv, s3n://insight-spark-after-dark/gender.csv.gz. Create an RDD called genders_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 1: There exists another zipped csv, s3n://insight-spark-after-dark/gender.csv.gz.\n",
    "# Create an RDD called genders_raw and read in the full gender file (UserId, gender).\n",
    "genders_raw = sc.textFile(\"s3n://insight-spark-after-dark/gender.csv.gz\")\n",
    "genders_raw.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gendersRDD = rawGendersRDD.map(rec_tup)\n",
    "gendersRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 2: Parse each of the record  from the genderRDDD so that we have a tuple of (gender(string), id(int)) and show \n",
    "split_rdd = genders_raw.map(lambda r: r.split(','))\n",
    "parsed_rdd = split_rdd.map(lambda r: (r[1], int(r[0])))\n",
    "parsed_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Calculate the distribution of Males, Females, and Unknowns and show the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have two RDDs with Key/Value pairs, use the join method to join the RDDs based on the Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(3)\n",
    "y = np.array(count)\n",
    "sns.barplot(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 3: Calculate the distribution of Males, Females, and Unknowns and show the results\n",
    "tagged_rdd = parsed_rdd.map(lambda r: (r[0], 1))\n",
    "distribution = tagged_rdd.reduceByKey(lambda x,y: x+y)\n",
    "distr = distribution.collect()\n",
    "gender = [str(val[0]) for val in distr]\n",
    "count = [val[1] for val in distr]\n",
    "\n",
    "print gender\n",
    "print count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Calculate the sum of all the IDs for each gender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Parse each of the record  from the genderRDDD so that we have a tuple of (gender(string), id(int)) and show \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 4: Calculate the sum of all the IDs for each gender\n",
    "id_sum_rdd = parsed_rdd.reduceByKey(lambda x,y: x+y)\n",
    "id_sum_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Calculate the average of all the IDs for each gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 5: Calculate the average of all the IDs for each gender\n",
    "sum_cnt_rdd = parsed_rdd.aggregateByKey((0,0),\n",
    "                                       lambda x,y: (x[0]+y, x[1]+1),\n",
    "                                       lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
    "avg_rdd = sum_cnt_rdd.mapValues(lambda r: r[0]/r[1])\n",
    "avg_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Only return records from parsed_rdd which have ids that are a multiple of 5 and show the first 5 results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 6: Only return records from parsed_rdd which have ids that are a multiple of 5 and \n",
    "# show the first 5 results\n",
    "filtered_rdd = parsed_rdd.filter(lambda r: r[1]%5==0)\n",
    "filtered_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
